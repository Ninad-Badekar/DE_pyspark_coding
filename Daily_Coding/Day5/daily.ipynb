{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "Problem Statement\n",
        "You have a PySpark DataFrame with total sales for different products. Write a PySpark program to calculate the percentage contribution of each product towards the total sales across all products.\n",
        "\n",
        "Sample Input (product_sales)\n",
        "product\tsales\n",
        "Laptop\t1200\n",
        "Phone\t800\n",
        "Tablet\t500\n",
        "Desktop\t500\n",
        "Expected Output\n",
        "product\tsales\tpercentage_contribution\n",
        "Laptop\t1200\t40.0\n",
        "Phone\t800\t26.7\n",
        "Tablet\t500\t16.7\n",
        "Desktop\t500\t16.7\n",
        "</pre>"
      ],
      "metadata": {
        "id": "YCcNatxyy_gL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "p0SO98SJyyYG"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql import Window\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('Daily-Day5').getOrCreate()"
      ],
      "metadata": {
        "id": "0c_jyuOIzNDd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "('Laptop',    1200),\n",
        "('Phone',    800),\n",
        "('Tablet'  ,  500),\n",
        "('Desktop',    500)]"
      ],
      "metadata": {
        "id": "uhwwYvt6zTxl"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema= ['product','sales']"
      ],
      "metadata": {
        "id": "ocFSVbtYzwpR"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "product_sales = spark.createDataFrame(data=data,schema=schema)"
      ],
      "metadata": {
        "id": "3NzR_0tUz3GR"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window = Window.partitionBy()"
      ],
      "metadata": {
        "id": "CYeDdxWB5ZjZ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum = product_sales.withColumn('sumOfSales', F.sum('sales').over(window))\n",
        "sum.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WLw2I620UlM",
        "outputId": "dd34254b-4e99-4404-d72e-4a6261934f02"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----------+\n",
            "|product|sales|sumOfSales|\n",
            "+-------+-----+----------+\n",
            "| Laptop| 1200|      3000|\n",
            "|  Phone|  800|      3000|\n",
            "| Tablet|  500|      3000|\n",
            "|Desktop|  500|      3000|\n",
            "+-------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = sum.withColumn('percentage_contribution',(F.col('sales')/F.col('sumOfSales'))*100).select(F.col('product'),F.col('sales'),F.col('percentage_contribution'))\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGsK5nBu0hI8",
        "outputId": "e56380c0-2b73-4869-848e-0c6931160899"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+-----------------------+\n",
            "|product|sales|percentage_contribution|\n",
            "+-------+-----+-----------------------+\n",
            "| Laptop| 1200|                   40.0|\n",
            "|  Phone|  800|     26.666666666666668|\n",
            "| Tablet|  500|     16.666666666666664|\n",
            "|Desktop|  500|     16.666666666666664|\n",
            "+-------+-----+-----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<pre>Problem Statement\n",
        "You have a SQL table transactions(txn_id, txn_date, amount). Write a query to find months in 2025 where there were no transactions. Assume txn_date is in YYYY-MM-DD format.\n",
        "\n",
        "Sample Input (transactions)\n",
        "txn_id\ttxn_date\tamount\n",
        "T1\t2025-01-10\t100\n",
        "T2\t2025-01-15\t200\n",
        "T3\t2025-03-05\t300\n",
        "T4\t2025-05-20\t400\n",
        "Expected Output\n",
        "missing_month\n",
        "2025-02\n",
        "2025-04\n",
        "2025-06\n",
        "2025-07\n",
        "2025-08\n",
        "2025-09\n",
        "2025-10\n",
        "2025-11\n",
        "2025-12\n",
        "</pre>"
      ],
      "metadata": {
        "id": "sRWm-9lN1vTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [('T1',\t'2025-01-10'\t,100),\n",
        "('T2'\t,'2025-01-15'\t,200),\n",
        "('T3',\t'2025-03-05',\t300),\n",
        "('T4',\t'2025-05-20',\t400)]\n",
        "schema =['txn_id',\t'txn_date',\t'amount']\n",
        "\n",
        "transactions = spark.createDataFrame(data=data,schema=schema)\n",
        "transactions = transactions.withColumn(\"txn_date\", F.to_date(\"txn_date\", \"yyyy-MM-dd\"))\n",
        "transactions.createOrReplaceTempView(\"transactions\")"
      ],
      "metadata": {
        "id": "ET_l-70l1tFc"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = spark.sql('''\n",
        "                    WITH months AS (\n",
        "  SELECT EXPLODE(\n",
        "    SEQUENCE(\n",
        "      TO_DATE('2025-01-01'),\n",
        "      TO_DATE('2025-12-01'),\n",
        "      INTERVAL 1 MONTH\n",
        "    )\n",
        "  ) AS month_start\n",
        ")\n",
        "SELECT\n",
        "  DATE_FORMAT(month_start, 'yyyy-MM') AS missing_month\n",
        "FROM months m\n",
        "LEFT JOIN (\n",
        "  SELECT DISTINCT DATE_FORMAT(txn_date, 'yyyy-MM') AS txn_month\n",
        "  FROM transactions\n",
        "  WHERE txn_date BETWEEN '2025-01-01' AND '2025-12-31'\n",
        ") t\n",
        "  ON DATE_FORMAT(month_start, 'yyyy-MM') = t.txn_month\n",
        "WHERE t.txn_month IS NULL\n",
        "ORDER BY month_start;\n",
        "''')\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAcJixpg2kAK",
        "outputId": "6f09df3f-5b55-4baf-a852-e7756e1f6f2d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "|missing_month|\n",
            "+-------------+\n",
            "|      2025-02|\n",
            "|      2025-04|\n",
            "|      2025-06|\n",
            "|      2025-07|\n",
            "|      2025-08|\n",
            "|      2025-09|\n",
            "|      2025-10|\n",
            "|      2025-11|\n",
            "|      2025-12|\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "to6KV_FN61YL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KzXoDujL3hkQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}