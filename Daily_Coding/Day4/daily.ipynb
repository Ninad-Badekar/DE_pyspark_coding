{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "Problem Statement\n",
        "You have a PySpark DataFrame with daily transaction amounts.\n",
        "For each day, identify transactions greater than the average \\\n",
        "amount for that day (outliers).\n",
        "\n",
        "Sample Input (transactions)\n",
        "txn_date\ttxn_id\tamount\n",
        "2025-01-01\tT1\t100\n",
        "2025-01-01\tT2\t200\n",
        "2025-01-01\tT3\t500\n",
        "2025-01-02\tT4\t300\n",
        "2025-01-02\tT5\t400\n",
        "2025-01-02\tT6\t600\n",
        "Expected Output\n",
        "txn_date\ttxn_id\tamount\n",
        "2025-01-01\tT3\t500\n",
        "2025-01-02\tT6\t600\n",
        "</pre>"
      ],
      "metadata": {
        "id": "YCcNatxyy_gL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "p0SO98SJyyYG"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql import Window\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('Daily-Day4').getOrCreate()"
      ],
      "metadata": {
        "id": "0c_jyuOIzNDd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [('2025-01-01','T1',100),\n",
        "('2025-01-01',\t'T2',\t200),\n",
        "('2025-01-01'\t,'T3'\t,500),\n",
        "('2025-01-02',\t'T4',\t300),\n",
        "('2025-01-02'\t,'T5'\t,400),\n",
        "('2025-01-02',\t'T6',\t600)]"
      ],
      "metadata": {
        "id": "uhwwYvt6zTxl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema= ['txn_date'\t,'txn_id'\t,'amount']"
      ],
      "metadata": {
        "id": "ocFSVbtYzwpR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transactions = spark.createDataFrame(data=data,schema=schema)"
      ],
      "metadata": {
        "id": "3NzR_0tUz3GR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window = Window.partitionBy('txn_date').orderBy('txn_date')"
      ],
      "metadata": {
        "id": "DNz-OLvGz8eZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg = transactions.withColumn('AveragePerDay', F.avg('amount').over(window))\n",
        "avg.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WLw2I620UlM",
        "outputId": "e210e62c-2b00-4d4f-b438-182514b8d2c1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+------+-----------------+\n",
            "|  txn_date|txn_id|amount|    AveragePerDay|\n",
            "+----------+------+------+-----------------+\n",
            "|2025-01-01|    T1|   100|266.6666666666667|\n",
            "|2025-01-01|    T2|   200|266.6666666666667|\n",
            "|2025-01-01|    T3|   500|266.6666666666667|\n",
            "|2025-01-02|    T4|   300|433.3333333333333|\n",
            "|2025-01-02|    T5|   400|433.3333333333333|\n",
            "|2025-01-02|    T6|   600|433.3333333333333|\n",
            "+----------+------+------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = avg.filter(F.col('amount')>F.col('AveragePerDay')).select(F.col('txn_date'),F.col('txn_id'),F.col('amount'))\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGsK5nBu0hI8",
        "outputId": "faf22aa9-7046-4d94-ed72-12abb8f65184"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+------+\n",
            "|  txn_date|txn_id|amount|\n",
            "+----------+------+------+\n",
            "|2025-01-01|    T3|   500|\n",
            "|2025-01-02|    T6|   600|\n",
            "+----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<pre>You have a table employee_manager(emp_id, manager_id, change_date)\n",
        "showing employees' managers over time.\n",
        "Write a SQL query to find employees who never changed their manager across all records.\n",
        "\n",
        "Sample Input (employee_manager)\n",
        "emp_id\tmanager_id\tchange_date\n",
        "1\t10\t2025-01-01\n",
        "1\t10\t2025-02-01\n",
        "2\t11\t2025-01-01\n",
        "2\t12\t2025-03-01\n",
        "3\t13\t2025-01-05\n",
        "Expected Output\n",
        "emp_id\n",
        "1\n",
        "3\n",
        "</pre>"
      ],
      "metadata": {
        "id": "sRWm-9lN1vTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(1\t,10\t,'2025-01-01'),\n",
        "(1\t,10\t,'2025-02-01'),\n",
        "(2,\t11\t,'2025-01-01'),\n",
        "(2\t,12,\t'2025-03-01'),\n",
        "(3,13,'2025-01-05')]\n",
        "schema =['emp_id'\t,'manager_id'\t,'change_date']\n",
        "\n",
        "employee_manager = spark.createDataFrame(data=data,schema=schema)\n",
        "employee_manager = employee_manager.withColumn(\"change_date\", F.to_date(\"change_date\", \"yyyy-MM-dd\"))\n",
        "employee_manager.createOrReplaceTempView(\"employee_manage\")"
      ],
      "metadata": {
        "id": "ET_l-70l1tFc"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = spark.sql('''\n",
        "                    SELECT emp_id\n",
        "                    FROM employee_manage\n",
        "                    GROUP BY emp_id\n",
        "                    HAVING count(DISTINCT manager_id) = 1''')\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAcJixpg2kAK",
        "outputId": "98eb3026-5e76-4598-82bd-3ca160ff027f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|emp_id|\n",
            "+------+\n",
            "|     1|\n",
            "|     3|\n",
            "+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KzXoDujL3hkQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}